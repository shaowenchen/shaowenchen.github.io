<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>LLM on 陈少文的网站</title><link>https://www.chenshaowen.com/tags/llm/</link><description>Recent content in LLM on 陈少文的网站</description><generator>Hugo -- gohugo.io</generator><language>zh</language><copyright>&amp;copy;2016 - {year}, All Rights Reserved.</copyright><lastBuildDate>Wed, 01 May 2024 00:00:00 +0000</lastBuildDate><sy:updatePeriod>weekly</sy:updatePeriod><atom:link href="https://www.chenshaowen.com/tags/llm/atom.xml" rel="self" type="application/rss+xml"/><item><title>对齐 Ops，使用新思路重写 Ops Copilot 已更新</title><link>https://www.chenshaowen.com/blog/ops-copilot-has-been-updated-using-pipeline-and-llm.html</link><pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate><atom:modified>Wed, 01 May 2024 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/ops-copilot-has-been-updated-using-pipeline-and-llm.html</guid><description>1. 让 Ops Copilot 成为 Ops Coilot 在 2023 年 09 月，我写过一版 Ops Copilot，也有文章发出 我在给 Ops 工具写 Copilot 。 实现的效果是这样的： 1 2 3 4 5 6 7 8 9 10 Opscli&amp;gt; 打开浏览器 Open a browser and navigate to &amp;#39;https://www.google.com&amp;#39;. ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ import webbrowser webbrowser.open(&amp;#39;https://www.google.com&amp;#39;) ↑↑↑↑↑↑↑↑↑↑↑</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>AI</category><category>Copilot</category><category>Agent</category><category>LLM</category></item><item><title>用了一个月，终于找到点写 AI Agent 的思路</title><link>https://www.chenshaowen.com/blog/provide-a-way-to-develop-ai-agent.html</link><pubDate>Sat, 16 Mar 2024 08:01:28 +0000</pubDate><atom:modified>Sat, 16 Mar 2024 08:01:28 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/provide-a-way-to-develop-ai-agent.html</guid><description>1. 不断尝试落地 AI 应用端 基于对运维的认知，我开发了一个开源的运维工具 https://github.com/shaowenchen/ops 。 Ops 工具将运维操作划分为脚本执行、文件分发两类，而运维对象主机和 Kubernetes 集群分别都实现了这两种运维操作。 Ops 对外提供的能力有，Ops Cli 命令行终端，Ops Server 服务端 API 接口，Ops Controller 集群</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>思考</category><category>AI</category><category>Agent</category><category>LLM</category><category>Ops</category></item><item><title>微信、公众号接入 GPT 服务</title><link>https://www.chenshaowen.com/blog/how-to-access-gpt-service-on-wechat.html</link><pubDate>Tue, 26 Dec 2023 00:00:00 +0000</pubDate><atom:modified>Tue, 26 Dec 2023 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/how-to-access-gpt-service-on-wechat.html</guid><description>提供有偿接入服务，200 RMB/年；另外，提供技术支持 200 RMB/次，不超过 1 hour；关注公众号，可获得联系方式。 1. 需要提供的信息 进入 https://mp.weixin.qq.com/ 在左侧菜单栏 【设置与开发】-&amp;gt; 【基本设置】，就能找到下面的信息 AppID 开发者 ID，可以明文直接查看到。 AppSecret</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>LLM</category><category>GPT</category><category>公众号</category><category>微信</category></item><item><title>大模型应用设计与实现指南</title><link>https://www.chenshaowen.com/blog/large-model-application-design-and-implementation-guide.html</link><pubDate>Sat, 23 Dec 2023 11:22:55 +0000</pubDate><atom:modified>Sat, 23 Dec 2023 11:22:55 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/large-model-application-design-and-implementation-guide.html</guid><description>1. 直接使用大模型面临的问题 输出不稳定性 生成式 AI 的特点之一，输出结果的多样性。同样一个问题，问大模型多次，可能会得到不同的答案。 这种输出的不确定性，在对话、创作场景下，会给用户带来惊喜。但在确定性要求比较高的场景下，大模型进入不了采纳阶段。 数</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>LLM</category><category>AI</category><category>最佳实践</category></item><item><title>我在给 Ops 工具写 Copilot</title><link>https://www.chenshaowen.com/blog/writing-copilot-for-my-ops-tool.html</link><pubDate>Sat, 23 Sep 2023 00:00:00 +0000</pubDate><atom:modified>Sat, 23 Sep 2023 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/writing-copilot-for-my-ops-tool.html</guid><description>1. 什么是 Ops 工具 https://www.chenshaowen.com/ops/ 是我日常运维最频繁使用的工具之一。 运维机器，我可以复用之前的脚本，批量进行操作。 运维集群，我可以复用之前的脚本，不用登录节点也可以操作机器。 如果遇到新的运维问题，我会马上编写 Task Yaml 对操作进行固化，方便下一次复用。 Ops 的核心操作是</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>大模型</category><category>思考</category><category>API</category><category>文档</category><category>LLM</category><category>Ops</category><category>Copilot</category></item><item><title>使用 CPU 推理 llama 结构的大模型</title><link>https://www.chenshaowen.com/blog/how-to-run-llama-on-cpu.html</link><pubDate>Sat, 16 Sep 2023 00:00:00 +0000</pubDate><atom:modified>Sat, 16 Sep 2023 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/how-to-run-llama-on-cpu.html</guid><description>1. 本地容器运行 启动 LLM 1 docker run --rm -p 8000:8000 shaowenchen/chinese-alpaca-2-7b-gguf:Q2_K 在 http://localhost:8000/docs 页面即可看到接口文档，如下图: 部署一个简单的 Chat UI 这里需要注意的是 OPENAI_API_HOST 参数，需要设置为你的宿主机 IP 地址，而不是 localhost 127.0.0.1，否则无法访问。 1 docker run -e OPENAI_API_HOST=http://{YOUR_HOST_IP}:8000 -e OPENAI_API_KEY=random -p 3000:3000 hubimage/chatbot-ui:main 页面效果如下: 2. K8s 快速部署 部署 LLM 应用 kubectl create</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>CPU</category><category>大模型</category><category>LLM</category><category>推理</category></item><item><title>AI 基础知识点</title><link>https://www.chenshaowen.com/blog/ai-basic-knowledge.html</link><pubDate>Fri, 18 Aug 2023 11:22:55 +0000</pubDate><atom:modified>Fri, 18 Aug 2023 11:22:55 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/ai-basic-knowledge.html</guid><description>1. 关键字 机器学习(ML) 从数据中自动获取知识的技术 神经网络(NN) 模仿生物神经网络结构和学习机制的模型，是机器学习的分支之一 神经网络的结构包括，输入层、隐藏层、输出层 深度神经网络(DNN) 隐含层常常大于 2 层 DNN 的出众表现源于它使用统计学方法从</description><dc:creator>微信公众号</dc:creator><category>整理</category><category>AI</category><category>LLM</category><category>机器学习</category><category>大模型</category></item></channel></rss>