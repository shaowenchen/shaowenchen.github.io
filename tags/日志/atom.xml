<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>日志 on 陈少文的网站</title><link>https://www.chenshaowen.com/tags/%E6%97%A5%E5%BF%97/</link><description>Recent content in 日志 on 陈少文的网站</description><generator>Hugo -- gohugo.io</generator><language>zh</language><copyright>&amp;copy;2016 - {year}, All Rights Reserved.</copyright><lastBuildDate>Wed, 06 Jul 2022 00:00:00 +0000</lastBuildDate><sy:updatePeriod>weekly</sy:updatePeriod><atom:link href="https://www.chenshaowen.com/tags/%E6%97%A5%E5%BF%97/atom.xml" rel="self" type="application/rss+xml"/><item><title>在 Kubernetes 集群上部署 Elasticsearch 栈</title><link>https://www.chenshaowen.com/blog/how-to-deploy-the-elasticsearch-stack-on-kubernetes.html</link><pubDate>Wed, 06 Jul 2022 00:00:00 +0000</pubDate><atom:modified>Wed, 06 Jul 2022 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/how-to-deploy-the-elasticsearch-stack-on-kubernetes.html</guid><description>如果采用 Logstash 集中接收 Filebeat 的日志输入，容易造成单点瓶颈；如果采用 Kafka 接收 Filebeat 的日志输入，日志的时效性又得不到保障。这里直接将 Filebeat 采集的日志直接输出到 Elasticsearch。 1. 准备工作 节点规划 这里没有区分 master、data、client 节点，而是</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>Kubernetes</category><category>Elasticsearch</category><category>日志</category></item><item><title>Logstash 配置基础</title><link>https://www.chenshaowen.com/blog/the-basic-configuration-of-logstash.html</link><pubDate>Tue, 07 Dec 2021 00:00:00 +0000</pubDate><atom:modified>Tue, 07 Dec 2021 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/the-basic-configuration-of-logstash.html</guid><description>1. Logstash 的基本原理 Logstash 是一个用于数据传输和处理的组件。 通过插件的组合，Logstash 可以满足各种日志采集的场景： logstash-&amp;gt;elasticsearch filebeat-&amp;gt;logstash-&amp;gt;elasticsearch filebeat-&amp;gt;kafka-&amp;gt;logstash-&amp;gt;elasticsearch filebeat-&amp;gt;redis-&amp;gt;logstash-&amp;gt;elasticsearch 2. Logstash 的基本配置 下面是一个 Logstash 的配置格式： 1 2 3 4 5 6 7 8 9 10 11 12 # 数据源，例如 Kafka、MySQL input { } # 过滤器，用于处理数</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>日志</category><category>配置</category><category>实践</category></item><item><title>ELK 日志搜索实践</title><link>https://www.chenshaowen.com/blog/elk-log-search-practice.html</link><pubDate>Sat, 03 Feb 2018 00:00:00 +0000</pubDate><atom:modified>Sat, 03 Feb 2018 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/elk-log-search-practice.html</guid><description>本文主要简单介绍了 ELK 的技术栈，并给出了 Docker compose 的编排配置。阅读本文，可在本地通过 Docker 将 ELK 跑起来。后续会将 ELK 在服务器上进行部署，相关的配置再补充。 1. ELK 技术栈介绍 ELK 其实并不是一款软件，而是一整套解决方案，是三个软件产品的首字母缩写，Elasticse</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>工具</category><category>日志</category><category>搜索</category></item></channel></rss>