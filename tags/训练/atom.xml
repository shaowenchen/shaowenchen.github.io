<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>训练 on 陈少文的网站</title><link>https://www.chenshaowen.com/tags/%E8%AE%AD%E7%BB%83/</link><description>Recent content in 训练 on 陈少文的网站</description><generator>Hugo -- gohugo.io</generator><language>zh</language><copyright>&amp;copy;2016 - {year}, All Rights Reserved.</copyright><lastBuildDate>Sun, 09 Feb 2025 10:00:00 +0000</lastBuildDate><sy:updatePeriod>weekly</sy:updatePeriod><atom:link href="https://www.chenshaowen.com/tags/%E8%AE%AD%E7%BB%83/atom.xml" rel="self" type="application/rss+xml"/><item><title>分布式计算框架 Ray</title><link>https://www.chenshaowen.com/blog/what-is-ray.html</link><pubDate>Sun, 09 Feb 2025 10:00:00 +0000</pubDate><atom:modified>Sun, 09 Feb 2025 10:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/what-is-ray.html</guid><description>1. 什么是 Ray 2016 年，UC Berkeley 的 RISELab 发布了一个新的分布式计算框架 Ray。 2017 年，发布 Ray 相关论文之后，受到业内的广泛关注，国内主要是蚂蚁集团采用并贡献了 Ray。 2020 年，Ray 发布了 1.0 版本，引入 Placement Group 特性，增加了用户自定义任务编排的灵活性，为后续的 Ray AI Libraries 和 vLLM 等</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>分布式</category><category>计算框架</category><category>Ray</category><category>训练</category><category>推理</category></item><item><title>使用 TensorBoard 可视化 PyTorch 训练过程</title><link>https://www.chenshaowen.com/blog/using-tensorboard-to-visualize-pytorch-training-process.html</link><pubDate>Sun, 17 Nov 2024 00:00:00 +0000</pubDate><atom:modified>Sun, 17 Nov 2024 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/using-tensorboard-to-visualize-pytorch-training-process.html</guid><description>1. 什么是 TensorBoard TensorBoard 主要是用来监控模型的各种指标的变化，比如 accuracy、loss、各种层的权重分布等。 TensorBoard 是 TensorFlow 的一个可视化工具，支持标量、文本、图像、音频、视频和 Embedding 等多种数据可视化，但是 PyTorch 也可以使用 TensorBoard。 2. 安装 tensorboard 1 pip install tensorboard 3. 使用</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>AI</category><category>PyTorch</category><category>TensorBoard</category><category>训练</category></item><item><title>使用 PyTorch 在 MNIST 数据集训练模型</title><link>https://www.chenshaowen.com/blog/using-pytorch-to-train-model-on-mnist-dataset.html</link><pubDate>Sat, 16 Nov 2024 00:00:00 +0000</pubDate><atom:modified>Sat, 16 Nov 2024 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/using-pytorch-to-train-model-on-mnist-dataset.html</guid><description>1. 创建训练脚本 创建训练脚本 mnist.py，内容如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>AI</category><category>PyTorch</category><category>训练</category><category>容器</category></item><item><title>Kubernetes 下的 DLRover 工作流程分析</title><link>https://www.chenshaowen.com/blog/kubernetes-dlrover-workflow-analysis.html</link><pubDate>Tue, 27 Aug 2024 00:00:00 +0000</pubDate><atom:modified>Tue, 27 Aug 2024 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/kubernetes-dlrover-workflow-analysis.html</guid><description>本文使用的 DLRover 版本是 0.3.7 1. DLRover Operator 1.1 启动 ElasticJob 和 ScalePlan 的控制器 实现代码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 创建 ElasticJob 的控制器 if err = controllers.NewElasticJobReconciler(mgr, masterImage).SetupWithManager(mgr); err != nil { setupLog.Error(err, &amp;#34;unable to create controller&amp;#34;, &amp;#34;controller&amp;#34;, &amp;#34;ElasticJob&amp;#34;) os.Exit(1) } // 创建 ScalePlan 的控制器 if err = controllers.NewScalePlanReconciler(mgr).SetupWithManager(mgr); err != nil { setupLog.Error(err, &amp;#34;unable to create controller&amp;#34;, &amp;#34;controller&amp;#34;, &amp;#34;ScalePlan&amp;#34;) os.Exit(1) } // 启动控制器 if err := mgr.Start(ctrl.SetupSignalHandler()); err != nil { setupLog.Error(err, &amp;#34;problem running manager&amp;#34;) os.Exit(1) } 这部分代码是</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>DLRover</category><category>Kubernetes</category><category>训练</category><category>故障自愈</category><category>源码</category></item><item><title>分布式训练中的数据并行架构</title><link>https://www.chenshaowen.com/blog/data-parallel-architecture-in-distributed-train.html</link><pubDate>Wed, 21 Aug 2024 00:00:00 +0000</pubDate><atom:modified>Wed, 21 Aug 2024 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/data-parallel-architecture-in-distributed-train.html</guid><description>1. Parameter Server 架构 在 Parameter Server 架构中，集群中的节点被分为两类，参数服务器节点（Parameter Server）和工作服务器节点（Worker）。 1.1 Parameter Server Parameter Server 用于存放模型的参数。 每个参数服务器节点负责管理和更新模型的一部分参数，而每个工作节点则只处理与其对应</description><dc:creator>微信公众号</dc:creator><category>整理</category><category>分布式</category><category>训练</category><category>数据并行</category><category>并行架构</category></item><item><title>使用 DLRover 托管作业进行弹性、容错训练</title><link>https://www.chenshaowen.com/blog/use-dlrover-to-manage-training-job.html</link><pubDate>Sat, 17 Aug 2024 00:00:00 +0000</pubDate><atom:modified>Sat, 17 Aug 2024 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/use-dlrover-to-manage-training-job.html</guid><description>1. 分布式训练面临的问题 预估训练资源困难，无法自动化 需要多少算力、需要多少时间、需要多少带宽、需要多少 CPU、需要多少内存，如果没有足够的积累，很难估算准确。导致的结果就是，超额申请、超额分配，造成极大的资源浪费。 需要去沉淀和提供解决方案。 故</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>DLRover</category><category>训练</category><category>Kubernetes</category><category>弹性训练</category><category>容错训练</category></item><item><title>模型并行训练技术</title><link>https://www.chenshaowen.com/blog/model-parallel-training-techniques.html</link><pubDate>Thu, 04 Apr 2024 00:00:00 +0000</pubDate><atom:modified>Thu, 04 Apr 2024 00:00:00 +0000</atom:modified><guid>https://www.chenshaowen.com/blog/model-parallel-training-techniques.html</guid><description>1. 数据并行 训练步骤: master 设备加载模型，并将模型参数复制到每个 worker 设备 master 设备按照 batch 维度划分训练数据，将每个 batch 传递给每个 worker 设备 每个 worker 设备进行训练 master 设备汇总每个 worker 设备的梯度，更新模型参数 master 设备广播模型参数到每个 worker 设备，准备下一个 batch 训练 核心思想: 将训练</description><dc:creator>微信公众号</dc:creator><category>博文</category><category>AI</category><category>训练</category><category>模型</category></item></channel></rss>